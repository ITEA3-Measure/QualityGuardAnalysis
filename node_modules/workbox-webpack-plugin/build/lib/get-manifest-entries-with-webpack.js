'use strict';

var _entries = require('babel-runtime/core-js/object/entries');

var _entries2 = _interopRequireDefault(_entries);

var _slicedToArray2 = require('babel-runtime/helpers/slicedToArray');

var _slicedToArray3 = _interopRequireDefault(_slicedToArray2);

var _getIterator2 = require('babel-runtime/core-js/get-iterator');

var _getIterator3 = _interopRequireDefault(_getIterator2);

function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj }; }

/*
  Copyright 2017 Google Inc.

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      https://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
*/

var getAssetHash = require('./utils/get-asset-hash');
var resolveWebpackUrl = require('./utils/resolve-webpack-url');

/**
 * A single manifest entry that Workbox can precache.
 * When possible, we leave out the revision information, which tells Workbox
 * that the URL contains enough info to uniquely version the asset.
 *
 * @param {Array<string>} knownHashes All of the hashes that are associated
 * with this webpack build.
 * @param {string} url webpack asset url path
 * @param {string} [revision] A revision hash for the entry
 * @return {module:workbox-build.ManifestEntry} A single manifest entry
 *
 * @private
 */
function getEntry(knownHashes, url, revision) {
  // We're assuming that if the URL contains any of the known hashes
  // (either the short or full chunk hash or compilation hash) then it's
  // already revisioned, and we don't need additional out-of-band revisioning.
  if (!revision || knownHashes.some(function (hash) {
    return url.includes(hash);
  })) {
    return { url };
  }
  return { revision, url };
}

/**
 * Filter to narrow down the asset list to chunks that:
 * - have a name.
 * - if there's a whitelist, the chunk's name is in the whitelist.
 * - if there's a blacklist, the chunk's name is not in the blacklist.
 *
 * TODO:
 *  Filter files by size:
 *    https://github.com/GoogleChrome/workbox/pull/808#discussion_r139606242
 *  Filter files that match `staticFileGlobsIgnorePatterns` (or something)
 *  but filter for [/\.map$/, /asset-manifest\.json$/] by default:
 *    https://github.com/GoogleChrome/workbox/pull/808#discussion_r140565156
 *
 * @param {Array<Object>} chunks webpack chunks.
 * @param {Array<string>} [whitelist] Chunk names to include.
 * @param {Array<string>} [blacklist] Chunk names to exclude.
 * @return {Array<Object>} Filtered array of chunks.
 *
 * @private
 */
function filterChunks(chunks, whitelist, blacklist) {
  return chunks.filter(function (chunk) {
    return 'name' in chunk && (!whitelist || whitelist.includes(chunk.name)) && (!blacklist || !blacklist.includes(chunk.name));
  });
}

/**
 * Takes in a list of webpack chunks, and returns a mapping of the path for each
 * file in the chunk to the associated hash for the entire chunk.
 *
 * @param {Array<Object>} chunks The webpack chunks.
 * @return {Object<string, string>} Mapping of paths to hashes.
 *
 * @private
 */
function mapChunksToChunkHashes(chunks) {
  var mapping = {};
  var _iteratorNormalCompletion = true;
  var _didIteratorError = false;
  var _iteratorError = undefined;

  try {
    for (var _iterator = (0, _getIterator3.default)(chunks), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {
      var chunk = _step.value;
      var _iteratorNormalCompletion2 = true;
      var _didIteratorError2 = false;
      var _iteratorError2 = undefined;

      try {
        for (var _iterator2 = (0, _getIterator3.default)(chunk.files), _step2; !(_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done); _iteratorNormalCompletion2 = true) {
          var file = _step2.value;

          mapping[file] = chunk.renderedHash;
        }
      } catch (err) {
        _didIteratorError2 = true;
        _iteratorError2 = err;
      } finally {
        try {
          if (!_iteratorNormalCompletion2 && _iterator2.return) {
            _iterator2.return();
          }
        } finally {
          if (_didIteratorError2) {
            throw _iteratorError2;
          }
        }
      }
    }
  } catch (err) {
    _didIteratorError = true;
    _iteratorError = err;
  } finally {
    try {
      if (!_iteratorNormalCompletion && _iterator.return) {
        _iterator.return();
      }
    } finally {
      if (_didIteratorError) {
        throw _iteratorError;
      }
    }
  }

  return mapping;
}

/**
 * Generate an array of manifest entries using webpack's compilation data
 *
 * TODO:
 *   Rename variables so they are easier to understand:
 *      https://github.com/GoogleChrome/workbox/pull/808#discussion_r139605624
 *      https://github.com/GoogleChrome/workbox/pull/808#discussion_r139605973
 *
 * @function getManifestEntriesWithWebpack
 * @param {Object} compilation webpack compilation
 * @param {module:workbox-webpack-plugin.Configuration} config
 * @return {Array<module:workbox-build.ManifestEntry>}
 *
 * @private
 */
module.exports = function (compilation, config) {
  var publicPath = compilation.options.output.publicPath;

  var whitelistedChunkNames = config.chunks;
  var blacklistedChunkNames = config.excludeChunks;
  var assets = compilation.assets,
      chunks = compilation.chunks;

  // If specified, only include chunks in config.chunks and exclude any chunks
  // named in config.excludeChunks.

  if (whitelistedChunkNames || blacklistedChunkNames) {
    chunks = filterChunks(chunks, whitelistedChunkNames, blacklistedChunkNames);
  }

  // Map all of the paths from the named chunks to their associated hashes.
  var pathsToHashes = mapChunksToChunkHashes(chunks);

  // If we're not in whitelist mode, then also include the paths we can infer
  // from compilation.assets in the final output.
  if (!whitelistedChunkNames) {
    var _iteratorNormalCompletion3 = true;
    var _didIteratorError3 = false;
    var _iteratorError3 = undefined;

    try {
      for (var _iterator3 = (0, _getIterator3.default)((0, _entries2.default)(assets)), _step3; !(_iteratorNormalCompletion3 = (_step3 = _iterator3.next()).done); _iteratorNormalCompletion3 = true) {
        var _ref = _step3.value;

        var _ref2 = (0, _slicedToArray3.default)(_ref, 2);

        var filePath = _ref2[0];
        var asset = _ref2[1];

        // If we already have a hash because this filePath was part of a chunk's
        // files, then we can skip calculating a hash.
        if (!(filePath in pathsToHashes)) {
          pathsToHashes[filePath] = getAssetHash(asset);
        }
      }
    } catch (err) {
      _didIteratorError3 = true;
      _iteratorError3 = err;
    } finally {
      try {
        if (!_iteratorNormalCompletion3 && _iterator3.return) {
          _iterator3.return();
        }
      } finally {
        if (_didIteratorError3) {
          throw _iteratorError3;
        }
      }
    }
  }

  var knownHashes = [compilation.hash, compilation.fullHash];
  var _iteratorNormalCompletion4 = true;
  var _didIteratorError4 = false;
  var _iteratorError4 = undefined;

  try {
    for (var _iterator4 = (0, _getIterator3.default)(compilation.chunks), _step4; !(_iteratorNormalCompletion4 = (_step4 = _iterator4.next()).done); _iteratorNormalCompletion4 = true) {
      var chunk = _step4.value;

      knownHashes.push(chunk.hash, chunk.renderedHash);
    }
    // Make sure we don't have any empty/undefined hashes.
  } catch (err) {
    _didIteratorError4 = true;
    _iteratorError4 = err;
  } finally {
    try {
      if (!_iteratorNormalCompletion4 && _iterator4.return) {
        _iterator4.return();
      }
    } finally {
      if (_didIteratorError4) {
        throw _iteratorError4;
      }
    }
  }

  knownHashes = knownHashes.filter(function (hash) {
    return !!hash;
  });

  var manifestEntries = [];
  var _iteratorNormalCompletion5 = true;
  var _didIteratorError5 = false;
  var _iteratorError5 = undefined;

  try {
    for (var _iterator5 = (0, _getIterator3.default)((0, _entries2.default)(pathsToHashes)), _step5; !(_iteratorNormalCompletion5 = (_step5 = _iterator5.next()).done); _iteratorNormalCompletion5 = true) {
      var _ref3 = _step5.value;

      var _ref4 = (0, _slicedToArray3.default)(_ref3, 2);

      var _filePath = _ref4[0];
      var hash = _ref4[1];

      var publicUrl = resolveWebpackUrl(publicPath, _filePath);
      var manifestEntry = getEntry(knownHashes, publicUrl, hash);
      manifestEntries.push(manifestEntry);
    }
  } catch (err) {
    _didIteratorError5 = true;
    _iteratorError5 = err;
  } finally {
    try {
      if (!_iteratorNormalCompletion5 && _iterator5.return) {
        _iterator5.return();
      }
    } finally {
      if (_didIteratorError5) {
        throw _iteratorError5;
      }
    }
  }

  return manifestEntries;
};